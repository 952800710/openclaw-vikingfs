#!/usr/bin/env python3
"""
OpenClaw-VikingFS æ¡¥æ¥æ¨¡å— v2
ç‹¬ç«‹ç‰ˆæœ¬ï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—
"""

import os
import json
import time
import re
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional, Tuple, Union

class VikingSummarizerSimple:
    """ç®€åŒ–çš„Vikingæ‘˜è¦å™¨"""
    
    def __init__(self, viking_root: str):
        self.viking_root = Path(viking_root)
    
    def generate_l0_summary(self, content: str) -> str:
        """ç”ŸæˆL0æ‘˜è¦ (50-100å­—ç¬¦)"""
        lines = content.split('\n')
        
        # æå–å…³é”®ä¿¡æ¯
        date_info = ""
        key_points = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # æå–æ—¥æœŸä¿¡æ¯
            if "202" in line and ("-" in line or "å¹´" in line):
                date_info = line[:50]
            
            # æå–å…³é”®ç‚¹
            if line.startswith("- ") or line.startswith("â€¢ "):
                key_points.append(line)
                if len(key_points) >= 3:
                    break
        
        # æ„å»ºæ‘˜è¦
        summary = ""
        if date_info:
            summary += date_info[:50]
        
        if key_points:
            for i, point in enumerate(key_points[:2]):
                if len(summary) < 80:  # æ§åˆ¶é•¿åº¦
                    if summary:
                        summary += " | "
                    summary += point.replace("- ", "").replace("â€¢ ", "")[:30]
        
        # ç¡®ä¿é•¿åº¦
        if len(summary) < 40:
            summary = content[:100].replace('\n', ' ').strip()
        
        return summary[:100]
    
    def generate_l1_overview(self, content: str) -> str:
        """ç”ŸæˆL1æ¦‚è§ˆ (200-500å­—ç¬¦)"""
        lines = content.split('\n')
        
        # æå–å…³é”®ç‚¹å’Œç« èŠ‚
        key_points = []
        chapters = []
        current_chapter = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            # è¯†åˆ«ç« èŠ‚
            if line.startswith("## "):
                current_chapter = line[3:].strip()
                chapters.append(current_chapter)
            
            # å…³é”®ç‚¹
            elif line.startswith("- ") or line.startswith("â€¢ ") or line.startswith("1."):
                if current_chapter:
                    key_points.append(f"{current_chapter}: {line}")
                else:
                    key_points.append(line)
        
        # æ„å»ºæ¦‚è§ˆ
        overview = "å…³é”®ç‚¹:\n"
        for i, point in enumerate(key_points[:5]):
            overview += f"  {i+1}. {point[:80]}\n"
        
        overview += "ç« èŠ‚:\n"
        for chapter in chapters[:3]:
            overview += f"  â€¢ {chapter}\n"
        
        return overview[:500]

class OpenClawVikingBridgeV2:
    """OpenClaw-VikingFSæ¡¥æ¥v2ç‰ˆ"""
    
    def __init__(self, workspace_root: str = None):
        self.workspace_root = Path(workspace_root or "/root/.openclaw/workspace")
        self.viking_root = self.workspace_root / "viking"
        self.summarizer = VikingSummarizerSimple(str(self.viking_root))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        self.viking_root.mkdir(exist_ok=True)
        for dir_name in ["memory/L0", "memory/L1", "memory/L2", "config", "integration"]:
            (self.viking_root / dir_name).mkdir(parents=True, exist_ok=True)
        
        # é…ç½®æ–‡ä»¶
        self.config_file = self.viking_root / "config" / "bridge_config.json"
        self.stats_file = self.viking_root / "config" / "bridge_stats.json"
        
        # åŠ è½½é…ç½®
        self.config = self.load_config()
        self.stats = self.load_stats()
        
        print(f"âœ… VikingFS Bridge v2 åˆå§‹åŒ–å®Œæˆ")
        print(f"   Workspace: {self.workspace_root}")
        print(f"   VikingFS: {self.viking_root}")
    
    def load_config(self) -> Dict:
        """åŠ è½½é…ç½®"""
        default_config = {
            "version": "2.0.0",
            "mode": "hybrid",  # hybrid|viking|traditional
            "auto_summarize": True,
            "cache_enabled": True,
            "token_optimization": True,
            "monitoring": True,
            "query_classifier": True
        }
        
        if self.config_file.exists():
            try:
                with open(self.config_file, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    return {**default_config, **user_config}
            except:
                return default_config
        return default_config
    
    def save_config(self):
        """ä¿å­˜é…ç½®"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def load_stats(self) -> Dict:
        """åŠ è½½ç»Ÿè®¡æ•°æ®"""
        default_stats = {
            "queries_total": 0,
            "queries_viking": 0,
            "tokens_total": 0,
            "tokens_saved": 0,
            "saving_rate_avg": 0.0,
            "query_types": {},
            "performance_history": []
        }
        
        if self.stats_file.exists():
            try:
                with open(self.stats_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except:
                return default_stats
        return default_stats
    
    def save_stats(self):
        """ä¿å­˜ç»Ÿè®¡æ•°æ®"""
        with open(self.stats_file, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, indent=2, ensure_ascii=False)
    
    def classify_query(self, query: str) -> Dict:
        """æŸ¥è¯¢åˆ†ç±»"""
        query_lower = query.lower()
        
        # ç®€å•åˆ†ç±»è§„åˆ™
        if any(word in query_lower for word in ["ä»€ä¹ˆæ—¶å€™", "æ—¥æœŸ", "æ—¶é—´", "å‡ å·"]):
            q_type = "factual_date"
            confidence = 0.9
        elif any(word in query_lower for word in ["æ£€æŸ¥", "çŠ¶æ€", "æŠ¥å‘Š", "æ€»ç»“"]):
            q_type = "administrative"
            confidence = 0.8
        elif any(word in query_lower for word in ["åˆ†æ", "ä¸ºä»€ä¹ˆ", "åŸå› ", "å¯¹æ¯”"]):
            q_type = "analytical"
            confidence = 0.7
        elif any(word in query_lower for word in ["å¦‚ä½•", "æ”¹è¿›", "åˆ›æ„", "å»ºè®®"]):
            q_type = "creative"
            confidence = 0.7
        elif any(word in query_lower for word in ["åˆ—å‡º", "æœ‰å“ªäº›", "ä»€ä¹ˆæŠ€èƒ½"]):
            q_type = "factual_list"
            confidence = 0.8
        elif "?" in query or "ï¼Ÿ" in query:
            q_type = "factual"
            confidence = 0.6
        else:
            q_type = "general"
            confidence = 0.5
        
        return {
            "type": q_type,
            "confidence": confidence,
            "original": query
        }
    
    def get_tier_strategy(self, query_type: str, confidence: float) -> List[str]:
        """æ ¹æ®æŸ¥è¯¢ç±»å‹ç¡®å®šå±‚çº§ç­–ç•¥"""
        if not self.config["query_classifier"]:
            return ["L0", "L1"]  # é»˜è®¤
        
        if query_type == "administrative":
            return ["L0"]
        elif query_type in ["factual_date", "factual_list", "factual"]:
            return ["L0", "L1"]
        elif query_type == "analytical":
            return ["L1", "L2"] if confidence > 0.7 else ["L0", "L1", "L2"]
        elif query_type == "creative":
            return ["L0", "L1", "L2"]
        else:
            return ["L0", "L1"]
    
    def load_tier_content(self, tier: str) -> str:
        """åŠ è½½æŒ‡å®šå±‚çº§çš„å†…å®¹"""
        tier_path = self.viking_root / "memory" / tier
        
        if not tier_path.exists():
            return ""
        
        # æŸ¥æ‰¾æœ€æ–°çš„è®°å¿†æ–‡ä»¶
        md_files = list(tier_path.glob("*.md"))
        if not md_files:
            return ""
        
        # å–æœ€æ–°çš„æ–‡ä»¶
        latest_file = sorted(md_files, key=lambda x: x.stat().st_mtime, reverse=True)[0]
        
        try:
            with open(latest_file, 'r', encoding='utf-8') as f:
                return f.read()
        except:
            return ""
    
    def query_memory(self, user_query: str) -> Dict:
        """ä¸»æŸ¥è¯¢æ¥å£"""
        start_time = time.time()
        
        # æŸ¥è¯¢åˆ†ç±»
        query_info = self.classify_query(user_query)
        
        # ç¡®å®šå±‚çº§ç­–ç•¥
        if self.config["mode"] == "traditional":
            tiers = ["L2"]
            strategy = "traditional"
        elif self.config["mode"] == "viking":
            tiers = ["L0", "L1"]
            strategy = "viking_only"
        else:  # hybrid
            tiers = self.get_tier_strategy(query_info["type"], query_info["confidence"])
            strategy = "hybrid"
        
        # åŠ è½½å†…å®¹
        content_parts = []
        for tier in tiers:
            tier_content = self.load_tier_content(tier)
            if tier_content:
                content_parts.append(f"--- {tier} ---\n{tier_content}")
        
        content = "\n\n".join(content_parts)
        
        # è®¡ç®—ç»Ÿè®¡
        response_chars = len(content)
        response_tokens = response_chars * 0.25
        
        # ä¼°ç®—ä¼ ç»Ÿæ–¹å¼
        l2_content = self.load_tier_content("L2")
        traditional_chars = len(l2_content)
        traditional_tokens = traditional_chars * 0.25 if traditional_chars > 0 else response_tokens * 3
        
        # è®¡ç®—èŠ‚çœ
        if traditional_tokens > 0:
            saving_rate = 1 - (response_tokens / traditional_tokens)
            tokens_saved = traditional_tokens - response_tokens
        else:
            saving_rate = 0.0
            tokens_saved = 0.0
        
        # æ›´æ–°ç»Ÿè®¡
        self.update_stats(query_info, response_tokens, traditional_tokens, saving_rate)
        
        # æ„å»ºå“åº”
        response_time = (time.time() - start_time) * 1000
        
        return {
            "content": content,
            "metadata": {
                "query": user_query,
                "query_type": query_info["type"],
                "confidence": query_info["confidence"],
                "strategy": strategy,
                "tiers_loaded": tiers,
                "response_chars": response_chars,
                "response_tokens": response_tokens,
                "traditional_tokens": traditional_tokens,
                "token_saving_rate": saving_rate,
                "tokens_saved": tokens_saved,
                "response_time_ms": response_time,
                "timestamp": datetime.now().isoformat()
            }
        }
    
    def update_stats(self, query_info: Dict, viking_tokens: float, 
                    traditional_tokens: float, saving_rate: float):
        """æ›´æ–°ç»Ÿè®¡"""
        self.stats["queries_total"] += 1
        self.stats["queries_viking"] += 1
        self.stats["tokens_total"] += viking_tokens
        self.stats["tokens_saved"] += (traditional_tokens - viking_tokens)
        
        # æ›´æ–°å¹³å‡èŠ‚çœç‡
        if self.stats["queries_total"] > 0:
            total_saved = self.stats["tokens_saved"]
            total_traditional = self.stats["queries_total"] * traditional_tokens
            if total_traditional > 0:
                self.stats["saving_rate_avg"] = total_saved / total_traditional
        
        # æ›´æ–°æŸ¥è¯¢ç±»å‹åˆ†å¸ƒ
        q_type = query_info["type"]
        if q_type not in self.stats["query_types"]:
            self.stats["query_types"][q_type] = 0
        self.stats["query_types"][q_type] += 1
        
        # è®°å½•æ€§èƒ½å†å²
        history_entry = {
            "query": query_info["original"][:50],
            "type": q_type,
            "viking_tokens": viking_tokens,
            "saving_rate": saving_rate,
            "time": datetime.now().isoformat()
        }
        
        self.stats["performance_history"].append(history_entry)
        if len(self.stats["performance_history"]) > 50:
            self.stats["performance_history"] = self.stats["performance_history"][-50:]
        
        # å®šæœŸä¿å­˜
        if self.stats["queries_total"] % 10 == 0:
            self.save_stats()
    
    def get_performance_dashboard(self) -> Dict:
        """è·å–æ€§èƒ½ä»ªè¡¨æ¿"""
        return {
            "summary": {
                "total_queries": self.stats["queries_total"],
                "viking_queries": self.stats["queries_viking"],
                "average_saving_rate": f"{self.stats['saving_rate_avg']:.1%}",
                "total_tokens_saved": f"{self.stats['tokens_saved']:,.0f}",
                "estimated_cost_saving_usd": f"${self.stats['tokens_saved'] * 0.000001:.2f}"
            },
            "query_type_distribution": self.stats["query_types"],
            "recent_performance": self.stats["performance_history"][-5:] if self.stats["performance_history"] else [],
            "configuration": {
                "mode": self.config["mode"],
                "token_optimization": self.config["token_optimization"],
                "auto_summarize": self.config["auto_summarize"]
            }
        }
    
    def migrate_openclaw_memory(self):
        """è¿ç§»OpenClawè®°å¿†åˆ°VikingFS"""
        print("ğŸ”„ å¼€å§‹è¿ç§»OpenClawè®°å¿†åˆ°VikingFS...")
        
        memory_dir = self.workspace_root / "memory"
        if not memory_dir.exists():
            print("âŒ æ‰¾ä¸åˆ°memoryç›®å½•")
            return False
        
        migrated_count = 0
        
        for mem_file in memory_dir.glob("*.md"):
            try:
                with open(mem_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç”Ÿæˆæ‘˜è¦
                l0_summary = self.summarizer.generate_l0_summary(content)
                l1_overview = self.summarizer.generate_l1_overview(content)
                
                # ä¿å­˜åˆ°VikingFS
                file_name = mem_file.name
                
                # L0
                l0_path = self.viking_root / "memory" / "L0" / file_name
                with open(l0_path, 'w', encoding='utf-8') as f:
                    f.write(l0_summary)
                
                # L1
                l1_path = self.viking_root / "memory" / "L1" / file_name
                with open(l1_path, 'w', encoding='utf-8') as f:
                    f.write(l1_overview)
                
                # L2 (ç¬¦å·é“¾æ¥)
                l2_path = self.viking_root / "memory" / "L2" / file_name
                if not l2_path.exists():
                    try:
                        os.symlink(str(mem_file.absolute()), str(l2_path))
                    except:
                        # å¦‚æœç¬¦å·é“¾æ¥å¤±è´¥ï¼Œå¤åˆ¶å†…å®¹
                        with open(mem_file, 'r', encoding='utf-8') as src, open(l2_path, 'w', encoding='utf-8') as dst:
                            dst.write(src.read())
                
                print(f"  âœ“ è¿ç§» {file_name}: {len(content)} â†’ {len(l0_summary)}/{len(l1_overview)} å­—ç¬¦")
                migrated_count += 1
                
            except Exception as e:
                print(f"  âœ— è¿ç§»å¤±è´¥ {mem_file}: {e}")
        
        print(f"âœ… è¿ç§»å®Œæˆ: {migrated_count} ä¸ªæ–‡ä»¶")
        return True

def test_bridge_v2():
    """æµ‹è¯•æ¡¥æ¥v2"""
    print("ğŸ§ª æµ‹è¯•VikingFS Bridge v2")
    print("=" * 60)
    
    # åˆå§‹åŒ–
    bridge = OpenClawVikingBridgeV2()
    
    # ç¡®ä¿æœ‰æ•°æ®
    bridge.migrate_openclaw_memory()
    
    print("\nğŸ” æµ‹è¯•æŸ¥è¯¢:")
    print("-" * 40)
    
    test_queries = [
        "ä»Šå¤©æ˜¯ä»€ä¹ˆæ—¥æœŸï¼Ÿ",
        "æ£€æŸ¥ç³»ç»ŸçŠ¶æ€",
        "æˆ‘å®‰è£…äº†å“ªäº›æŠ€èƒ½ï¼Ÿ",
        "åˆ†æä¸€ä¸‹æˆ‘ä»¬çš„æ”¹é€ æ–¹æ¡ˆ",
        "å¦‚ä½•æ”¹è¿›è¿™ä¸ªç³»ç»Ÿï¼Ÿ"
    ]
    
    for query in test_queries:
        print(f"\nğŸ“ æŸ¥è¯¢: {query}")
        result = bridge.query_memory(query)
        meta = result["metadata"]
        
        print(f"  ç±»å‹: {meta['query_type']} (ç½®ä¿¡åº¦: {meta['confidence']:.2f})")
        print(f"  ç­–ç•¥: {meta['strategy']}")
        print(f"  å±‚çº§: {meta['tiers_loaded']}")
        print(f"  å­—ç¬¦æ•°: {meta['response_chars']:,}")
        print(f"  Tokenä¼°ç®—: {meta['response_tokens']:.0f}")
        print(f"  ä¼ ç»ŸToken: {meta['traditional_tokens']:.0f}")
        print(f"  èŠ‚çœç‡: {meta['token_saving_rate']:.1%}")
        print(f"  å“åº”æ—¶é—´: {meta['response_time_ms']:.1f}ms")
    
    # æ˜¾ç¤ºä»ªè¡¨æ¿
    print("\nğŸ“Š æ€§èƒ½ä»ªè¡¨æ¿:")
    print("-" * 40)
    
    dashboard = bridge.get_performance_dashboard()
    summary = dashboard["summary"]
    
    print(f"æ€»æŸ¥è¯¢æ•°: {summary['total_queries']}")
    print(f"å¹³å‡èŠ‚çœç‡: {summary['average_saving_rate']}")
    print(f"æ€»èŠ‚çœToken: {summary['total_tokens_saved']}")
    print(f"ä¼°ç®—æˆæœ¬èŠ‚çœ: {summary['estimated_cost_saving_usd']}")
    
    print("\næŸ¥è¯¢ç±»å‹åˆ†å¸ƒ:")
    for q_type, count in dashboard["query_type_distribution"].items():
        print(f"  {q_type}: {count}")
    
    return bridge

if __name__ == "__main__":
    bridge = test_bridge_v2()